**Out-Of-Core Learning** refers to a technique in machine-learning where models are trained on datasets that are too long to fit into a company's memory (RAM). 
- This process enables the processing of large-scale datasets efficiently by breaking the data into smaller chunks or batches and processing them incrementally 

#### Memory Limitation
- Traditionally machine learning algorithms typically require the entire datasets to be loaded into memory for training
- When the datasets exceeds available memory, it becomes impractical 